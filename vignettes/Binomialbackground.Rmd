---
title: "Group Sequential Design for Binary Outcomes"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: flatly
    highlight: tango
    code_folding: hide
bibliography: gsDesign.bib
vignette: |
  %\VignetteIndexEntry{Group Sequential Design for Binary Outcomes}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(tibble)
library(dplyr)
library(knitr)
library(gsdmvn)
```

## Overview

We consider group sequential design comparing two binomial distributions based on comparing two treatment groups for a binary outcome.
There are several issues to consider:

- The measure of treatment difference or natural parameter; we focus on risk difference.
- Null and alternate hypothesis variance incorporation.
- Superiority, non-inferiority and super-superiority designs.
- Stratified populations.
- Fixed and group sequential designs.

The focus here is for sample sizes that are large enough so that asymptotic theory works well without continuity corrections.
Simulation is used throughout to demonstrate how to check this assumption as well as to check the examples presented.

## Single analysis unstratified

### Notation and asymptotic distribution

Throughout we assume a control group and a single experimental group indexed by $C$ and $E$, respectively.
We also focus on pairwise comparisons.
We assume for control and experimental groups, respectively:

- Randomization between two treatment groups with sample sizes $N_C$ and $N_E$; the randomization ratio planned is $r=N_E/N_C$.
- Independent observations with a binary outcome that is observed with probability $p_C$ and $p_E$.
- Random variables $X_C\sim\hbox{Binomial}(N_C, p_C), X_E\sim\hbox{Binomial}(N_E,p_E)$ with observed outcomes $x_C, x_E$ and observed rates of $\bar p_C=x_C/N_C, \bar p_E=x_E/N_E$.  
- The constant $d=\pm 1$ indicating whether is an outcome is bad (failure; $d=1$) or good (response; $d=-1$).
- The natural parameter risk difference is denoted by $\theta = d\times (p_C - p_E)$. Thus, whether $d=1$ or $d=-1$, $\theta > 0$ indicates a more favorable outcome distribution in the experimental group than in the control group.
- Estimation of risk difference with $\hat\theta=d\times(\bar p_C - \bar p_E).$

Letting $N=N_C+N_E$, we note that $N_C=N/(r+1)$ and $N_E=Nr/(r+1)$.
We have $E(\hat\theta)=\theta$ and 

$$
\begin{aligned}
\sigma^2 &= \hbox{Var}(\hat\theta)= \frac{p_C(1- p_C)}{N_C}+\frac{p_E(1- p_E)}{N_E}\\
 &= \frac{r+1}{N}\left(p_C(1- p_C)+\frac{p_E(1- p_E)}{r}\right).
\end{aligned}
$$



### Testing

We will formulate hypothesis testing with two fixed real values $\theta_0 < \theta_1$, a null hypothesis $H_0: \theta=\theta_0$ and alternate hypothesis $H_a: \theta=theta_1$.
Testing will be one-sided at level $\alpha, 0<\alpha<1$, with the null hypothesis being rejected if 
$$Z-\theta_0\ge \Phi^{-1}(1-\alpha).$$
where 

$$Z=\frac{d\times(\bar p_C - \bar p_E)}{\hat\sigma_0}$$
and $\hat\sigma^2_0$ is the maximum likelihood estimate of the variance $\sigma^2$ under $H_0$.
Letting $\bar p=(x_C+x_E)/(N_C+N_E)$ we have 
$$\hat\sigma^2_0 = \bar p (1-\bar p)\times \left(\frac{1}{N_C}+\frac{1}{N_E}\right)= \bar p (1-\bar p)\frac{r+1}{N}\left(1 + \frac{1}{r}\right).$$
Note that when we have equal randomization, this has the perhaps more recognizable 
$$\hat\sigma^2_0 = \frac{4}{N}\bar p (1-\bar p).$$

We do a quick 20,000 simulations and compare the density histogram of outcomes to the standard normal density.
Assume $r=1, d = 1, p_C=p_E=0.125, N=200$.
We then compute $\sigma$ as `r round(sqrt(.125 * .875/200 * 4), 3)`.
Even for this *not huge* sample size the normal density fits quite well other than some flatness in the middle.


```{r, message = FALSE}
# Hypothesized failure rate
p <- .125
#  Other parameters
set.seed(123)
r <- 1
N <- 200
NC <- N / (r + 1)
NE <- r * N / (r + 1)
library(ggplot2)
# Generate random counts of events for each treatment
xC <- rbinom(n = 20000, size = NC, prob = p)
xE <- rbinom(n = 20000, size = NE, prob = p)
# Treatment difference estimate
thetahat <- xC / NC - xE / NE
# Standard error under H0
pbar <- (xC + xE) / N
se0 <- sqrt(pbar * (1 - pbar)*(1 / NC + 1 / NE))
# Z to test H0
Z <- thetahat / se0
x <- seq(-4, 4, .1)
se0a <- sqrt(p * (1 - p) * (1 / NC + 1 / NE))
y <- data.frame(Z = x, Density = dnorm(x = x, mean = 0, sd = 1)) 
ggplot() + 
  geom_histogram(data = data.frame(Z), aes(x = Z, y = ..density..), color = 1, fill = "white") +
    ylab("Density") +
  geom_line(data = y, aes(x=Z, y = Density)) +
  ggtitle("Binomial outcomes by simulation vs. asymptotic normal density",
          subtitle = "Histogram for 20,000 simulations")
```

Now we extend the computation of $\hat\sigma^2_0$ to $\theta_0\neq 0$ using the restrictions that rate estimates $\bar p_{C0}, \bar p_{E0}$ under the null hypothesis satisfies $\bar p_{C0}=\bar p_{E0}+d\theta_0$ and 
$p_{C0} + rp_{E0} = p_C + rp_C $.
Simple algebra for 2 equations with 2 unknowns yields

$$
\begin{aligned}
p_{E0} = &\frac{p_C+rp_E - d\theta_0}{r+1}\\
p_{C0} = & p_{E0}+ d\theta_0.
\end{aligned}
$$
Now we have
$$\hat\sigma^2_0= \frac{\bar p_{C0}(1- \bar p_{C0})}{N_C}+\frac{\bar p_{E0}(1- \bar p_{E0})}{N_E}= \frac{r+1}{N}\left(\bar p_{C0}(1- \bar p_{C0})+\frac{\bar p_{E0}(1- \bar p_{E0})}{r}\right).
$$


Assuming $0 < x_C<N_C$ and $0<x_E<N_E$ we will estimate the above variance with:

$$\hat\sigma^2=\widehat{\hbox{Var}}(\hat\theta)=\frac{\bar p_C(1- \bar p_C)}{N_C}+\frac{\bar p_E(1- \bar p_E)}{N_E}.$$
We will use the asymptotic approximation $Z=\hat\theta/\hat\sigma\sim\hbox{Normal}(\delta, 1)$ where $\delta=d\times(p_C-p_E)/\sigma$ is the standardized effect size.
Squaring this and applying a continuity correction is a typical two-sided testing approach, but we will not use the continuity correction here . 
Using the normally distributed $Z$ enables one-sided testing. 
The continuity correction is generally unneeded (@CCmyth) and as demonstrated below and from .

### Sample size and power

Same; include simulation for both Type I error and power.

## Stratified population

### Assumptions

### Weighting options

## Group sequential design

## Information-based design

## References
