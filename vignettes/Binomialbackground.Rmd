---
title: "Group Sequential Design for Binary Outcomes"
output:
  rmarkdown::html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: flatly
    code_folding: hide
    number_sections: true
    highlight: "textmate"
    css: "custom.css"
bibliography: gsDesign.bib
vignette: |
  %\VignetteIndexEntry{Group Sequential Design for Binary Outcomes}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

library(tibble)
library(dplyr)
library(knitr)
#library(gsdmvn)
devtools::load_all()
library(gsDesign)
```



# Overview

We consider group sequential design examining the risk difference between two treatment groups for a binary outcome.
There are several issues to consider:

- The measure of treatment difference or natural parameter; we focus on risk difference.
- Incorporation of both null and alternate hypothesis variances.
- Superiority, non-inferiority and super-superiority designs.
- Stratified populations.
- Fixed and group sequential designs.

For single stratum designs, we focus on sample size or power using the method of
@FarringtonManning for a trial to test the difference between two
binomial event rates.
The routine can be used for a test of superiority, non-inferiority or super-superiority. 
For a design that tests for superiority, the methods are consistent with those of @FTU, but without the
continuity correction. 
Methods for sample size and power are the same as `gsDesign::nBinomial()` when testing on the risk-difference scale for a single stratum. 
This is also consistent with the **Hmisc** R package routines `bsamsize()` and
`bpower()` for superiority designs.

For trials with multiple strata, testing for a risk difference is often done by weighting each stratum according to the inverse of the variance (@MantelHaenszel).
Since risk differences may also be assumed to be different for different strata, we will also explore weighting by strata sample sizes as in @Mehrotra2000.

The focus here is for sample sizes that are large enough for asymptotic theory to work well without continuity corrections.
The concepts are incorporated in the following functions intended for use in fixed and group sequential designs:

- `gs_info_rd()` to support asymptotic variance and statistical information calculation.
- `gs_power_rd()` to support power calculations.
- `gs_design_rd()` to support sample size calculations.

Simulation is used throughout to check the examples presented.


# Notation

- $K$: total number of analyses (including the final analysis) in the group sequential design. For fixed design, $K= 1$.

- $S$: total number of strata. If the population is un-stratified population, then $S=1$.

- $w_{s,k}$: the weight assigned for the $s$-th strata at the $k$-th analysis. 
  + For an un-stratified population, $S = 1$ and $w_{1,k} = 1$ for $k=1,\ldots, K$.
  + For an stratified population, see Section 4.

- $N_{C,k,s}$: sample size in the control group at the $k$-th analysis of the $s$-th strata. WHY SWITH ORDER OF s, k FROM w?

- $N_{E,k,s}$: sample size in the treatment group at the $k$-th analysis of the $s$-th strata.

- $r$: planned randomization ratio, i.e., 
$$
  r = N_{E,k,s} / N_{C,k,s} \;\; \forall k = 1, \ldots, K \;\; \text{and} \;\; s = 1, \ldots, S.
$$

- $N_{k,s}$: total sample size at the $k$-th analysis of the $s$-th strata, i.e, 
$$
  \begin{array}{l}
    N_{k,s} = N_{C,k,s} + N_{E,k,s} \\
    N_{C,k,s} = N_{k,s} / (r+1) \\
    N_{E,k,s} = rN_{k,s} /(r+1)
  \end{array}
$$

- $N_k$: total (INCREMENTAL OR CUMULATIVE?) sample size at the $k$-th analysis, i.e.,
$$
  N_k = \sum_{s=1}^S N_{k,s} = \sum_{s=1}^S (N_{C,k,s} + N_{E,k,s}).
$$

- $N$: total sample size, i.e., I THINK THIS IS WRONG; YOU HAVE USED $N_k$ AS TOTAL SAMPLE SIZE AT ANALYSIS $k$.
$$
  N = N_K = \sum_{k=1}^K N_k = \sum_{k=1}^K \sum_{s=1}^S (N_{C,k,s} + N_{E,k,s}).
$$

- $p_{C,k,s}$: independent observations in the control group with a binary outcome that is observed with probability $p_{C,k,s}$ at the $k$-th analysis of the $s$-th strata. SHOULD WE SIMPLIFY THIS TO $p_{C,s}$; i.e., ASSUME CONSTANT FOR ALL k? SAME FOR NEXT BULLET

- $p_{E,k,s}$: independent observations in the treatment group with a binary outcome that is observed with probability $p_{E,k,s}$ at the $k$-th analysis of the $s$-th strata.

- $d_{k,s}$: an indicator whether is an outcome is failure (bad outcome) or response (good outcome), i.e.,
$$
  d_{k,s}
  = 
  \left\{
  \begin{array}{ll}
    -1 & \text{if } p_{C,k,s} < p_{E,k,s} \\
     1 & \text{if } p_{C,k,s} \geq p_{E,k,s} \\
  \end{array}
  \right.
$$


- $X_{C,k,s}$: random variables $X_{C,k,s} \sim \hbox{Binomial}(N_{C,k,s}, p_{C,k,s})$ at the $k$-th analysis of the $s$-th strata.

- $X_{E,k,s}$: random variables $X_{E,k,s} \sim \hbox{Binomial}(N_{E,k,s}, p_{E,k,s})$ at the $k$-th analysis of the $s$-th strata.

- $x_{C,k,s}$: the observed outcome of $X_{C, k, s}$ at the $k$-th analysis of the $s$-th strata.

- $x_{E,k,s}$: the observed outcome of $X_{E, k, s}$ at the $k$-th analysis of the $s$-th strata.

- $\widehat p_{C,k,s}$: observed rates of the control group at the $k$-th analysis of the $s$-th strata, i.e., 
$$
  \widehat p_{C,k,s} = x_{C,k,s} / N_{C,k,s}.
$$

- $\widehat p_{E,k,s}$: observed rates of the control group at the $k$-th analysis of the $s$-th strata, i.e., 
$$
  \widehat p_{E,k,s} = x_{E,k,s} / N_{E,k,s}.
$$

- $\theta_{k,s}$: the natural parameter risk difference at the $k$-th analysis of the $s$-th strata is denoted by (LAST PART DOES NOT LOOK CORRECT; I WOULD NOT PUT IN ABSOLUTE VALUE)
$$
  \theta_{k,s} = d_{k,s} \times (p_{C,k,s} - p_{E,k,s}) = |p_{C,k,s} - p_{E,k,s}|. 
$$ 
Thus, whether $d_{k,s} = 1$ or $d_{k,s} = -1$, $\theta_{k,s} > 0$ indicates a more favorable outcome distribution in the experimental group than in the control group.

- $\hat\theta_{k,s}$: estimation of risk difference with 
$$
  \widehat\theta_{k,s} = d_{k,s} \times (\widehat p_{C,k,s} - \widehat p_{E,k,s})
$$
We have $E(\widehat\theta_{k,s}) = \theta_{k,s}$.


# Testing

The test statistics at the $k$-th analysis is
$$
  Z_{k} 
  = 
  \frac{ 
    \sum_{s=1}^S w_{s,k} \; d_{s,k} \times \left( \widehat \delta_{k,s} - \delta_{k,s}^{null} \right)
  }{
    \sqrt{\sum_{s=1}^S w_{s,k}^2 \widehat\sigma_{H_0,k,s}^2}
  }
$$
where $\widehat\sigma^2_{H_0,k,s}$ is the null hypothesis estimate of the $\hbox{Var}(\widehat p_C -\widehat p_E)$. 
And the value of  $\widehat\sigma^2_{H_0,k,s}$ depends on the design, i.e., whether it is a superiority design, or non-inferiority design, or super-superiority design. 
We will discuss $\widehat\sigma^2_{H_0,k,s}$ in the following 3 subsections.


## Superiority Design

A superiority design is to show that xperimental group is superior to the control group above some thresholds.
Its hypothesis is
$$
  H_0: \delta_{k,s} = 0 \text{ vs. } H_1: \delta_{k,s} > 0,
$$
for any $k = 1, \ldots, K$ and $s = 1, \ldots, S$.

- **Variance per strata per analysis:**
  + Under the null hypothesis, we have

$$
  \widehat\sigma^2_{H_0,k,s} 
  = 
  \widehat{\text{Var}}(\hat p_C - \hat p_E | H_0)
  =
  \widehat p_{k,s}^{pool} \left(1 - \widehat p^{pool}_{k,s} \right) \left(\frac{1}{N_{C,k,s}} + \frac{1}{N_{E,k,s}} \right),
$$

where $\widehat p_{k,s}^{pool}$ is the estimated pooled observed rates of two groups at the $k$-th analysis of the $s$-th strata, i.e, 
$\widehat p_{k,s}^{pool} = (x_{C,k,s} + x_{E,k,s}) / (N_{C,k,s} + N_{E,k,s}).$
  
  + Under the alternative hypothesis, we have

$$
  \begin{array}{ll}
  \sigma_{H_1,k,s}^2 
  & = 
  \text{Var}(\hat p_C - \hat p_E | H_1)
  = 
  \frac{p_{C,k,s} (1- p_{C,k,s})}{N_{C,k,s}} + \frac{p_{E,k,s} (1 - p_{E,k,s})}{N_{E,k,s}} \\
  & = 
  \underbrace{(r+1)\left[p_{C,k,s} (1 - p_{C,k,s}) + p_{E,k,s} (1 - p_{E,k,s})/r \right]}_{\psi_{k,s}^2} / N_{k,s},
  \end{array}
$$
which can be estimated as

$$
  \widehat\sigma_{H_1,k,s}^2 
  = 
  \widehat{\text{Var}}(\hat p_C - \hat p_E | H_1)
  = 
  \frac{\widehat p_{C,k,s} (1- \widehat p_{C,k,s})}{N_{C,k,s}} + \frac{\widehat p_{E,k,s} (1 - \widehat p_{E,k,s})}{N_{E,k,s}},
$$
where 
$\widehat p_{C,k,s} = x_{C,k,s} / N_{C,k,s} \text{ and } \widehat p_{E,k,s} = x_{E,k,s} / N_{E,k,s}$.
Testing will be one-sided at level $\alpha \in (0, 1)$ and the null hypothesis will be rejected if $Z_k$ cross the upper boundary. 
And the upper boundary can be either fixed or derived from spending functions.


- **Standardized treatment effect per analysis:**
  + Under the null hypothesis, we have
$$
  \theta_{H_0,k} = 0.
$$

  + Under the alternative hypothesis, we have
$$
  \theta_{H_1,k} = \frac{\sum_{s=1}^S w_{k,s} (p_C - p_E)}{\sum_{s=1}^S w_{k,s}^2 \sigma_{H_1, k,s}^2},
$$
which can be estimated as
$$
  \widehat\theta_{H_1,k} = \frac{\sum_{s=1}^S w_{k,s} (\widehat p_C - \widehat p_E)}{\sum_{s=1}^S w_{k,s}^2 \widehat\sigma_{H_1, k,s}^2}.
$$


- **Standardized information per analysis:**
  
  @LachinBook or @Lachin1981 provide fixed sample size calculations based on the values $\psi_0$ under the null hypothesis and $\psi_1$ under the alternate hypothesis. 
Here we propose using the same variance calculations to compute statistical information for a group sequential design and apply the formulation for power and sample size calculation in the vignette _Computing Bounds Under Non-Constant Treatment Effect_.

  + Under the null hypothesis, we have

$$
  \widehat{\mathcal I}_{H0,k} = \left[ \sum_{s=1}^S \frac{p_{k,s}^{pool} (1 - p_{k,s}^{pool})}{N_{k,s}} \right]^{-1},
$$
where $\widehat p_{k,s}^{pool} = (x_{C,k,s} + x_{E,k,s}) / (N_{C,k,s} + N_{E,k,s})$ and $N_{k,s} = N_{C, k, s} + N_{E, k, s}$.
 
  + Under the alternative hypothesis, we have

$$
  \widehat{\mathcal I}_{H1,k} 
  = 
  \left[ 
    \sum_{s=1}^S w_{k,s}^2 \frac{\widehat p_{C,k,s} (1 - \widehat p_{C,k,s})}{N_{C,k,s}}
    +
    \sum_{s=1}^S w_{k,s}^2 \frac{\widehat p_{E,k,s} (1 - \widehat p_{E,k,s})}{N_{E,k,s}} 
  \right]^{-1}.
$$


## Super-Superiority Design 

The hypothesis of the super-superiority design is

$$
  H_0: \delta_{k,s} = \delta_{k,s}^{null} 
  \;\; vs. \;\; 
  H_1: \delta > \delta_{k,s}^{null} \text{ with } \delta_{k,s}^{null} > 0.
$$
Here $\theta_{k,s_1}^{null} = \theta_{k,s_2}^{null}$ or $\theta_{k,s_1}^{null} \neq \theta_{k,s_2}^{null}$ for $s_1 \neq s_2$.

Under the null hypothesis $\theta_{0,k,s} \neq 0$, the estimation of rates $\widehat p_{C0,k,s}, \widehat p_{E0,k,s}$ satisfy 
$$
  \left\{
  \begin{array}{l}
    \widehat p_{C0,k,s} = \widehat p_{E0,k,s} + d_{k,s} \times \delta_{k,s}^{null} \\
    \widehat p_{C0,k,s} + r\widehat p_{E0,k,s} = \widehat p_{C,k,s} + r\widehat p_{E,k,s} .
  \end{array}
  \right.
$$
Solving these 2 equations with 2 unknowns yields
$$
  \left\{
  \begin{array}{l}
  \widehat p_{E0,k,s} & = (\widehat p_{C,k,s} + r \widehat p_{E,k,s} - d_{k,s} \delta_{k,s}^{null}) / (r + 1)\\
  \widehat p_{C0,k,s} & =  \widehat p_{E0,k,s} + d_{k,s} \delta_{k,s}^{null}.
  \end{array}
  \right.
$$

- **Variance per strata per analysis:**
  + Under $H_0$, we have 


$$
  \hat\sigma^2_{H_0,k,s}
  = 
  \frac{\widehat p_{C0,k,s}(1- \widehat p_{C0,k,s})}{N_{C,k,s}} + \frac{ \widehat p_{E0,k,s} (1 - \widehat p_{E0,k,s})}{N_{E,k,s}}.
$$
  
  + Under $H_1$, we have

$$
  \widehat\sigma_{H_1,k,s}^2 
  = 
  \frac{\widehat p_{C,k,s} (1- \widehat p_{C,k,s})}{N_{C,k,s}} + \frac{\widehat p_{E,k,s} (1 - \widehat p_{E,k,s})}{N_{E,k,s}}.
$$


- **Standardized treatment effect per analysis:**
  + Under the null hypothesis, we have

$$
  \widehat \theta_{H_0,k} 
  = 
  \frac{
    \sum_{s=1}^S w_{k,s} \delta_{s,k}^{null}
  }{
    \sqrt{\sum_{s=1}^S w_{k,s}^2 \widehat \sigma_{H_0,k,s}}^2
  }.
$$

  + Under the alternative hypothesis, we have

$$
  \widehat \theta_{H_1} 
  = 
  \frac{
    \sum_{s=1}^S w_{k,s} d_{k,s} \times (\widehat p_{C,k,s} - \widehat p_{E,k,s})
  }{
    \sqrt{\sum_{s=1}^S w_{k,s}^2 \widehat \sigma_{H_1,k,s}^2}
  }.
$$

- **Standardized information per analysis:**
  + Under the null hypothesis, we have

$$
  \widehat{\mathcal I}_{H0,k} 
  = 
  \left[ 
  \sum_{s=1}^S w_{k,s}^2 \frac{\bar p_{C0,s} (1 - \bar p_{C0,s})}{N_{C,s}} + w_{k,s}^2\frac{\bar p_{E0,s} (1 - \bar p_{E0,s})}{N_{E,s}} 
  \right]^{-1}.
$$
 
  + Under the alternative hypothesis, we have

$$
  \widehat{\mathcal I}_{H1,k} 
  = 
  \left[
  \sum_{s=1}^S \left( w_{k,s}^2 \frac{\bar p_{C,k,s} (1 - \bar p_{C,k,s})}{N_{C,k,s}} + w_{k,s}^2 \frac{\bar p_{E,k,s} (1 - \bar p_{E,k,s})}{N_{E,k,s}} \right)
  \right]^{-1}.
$$


## Non-inferiority Design

The non-inferiority Design means that, while the treatment group is definitely not better than the control group, it is not unacceptably worse.
Its hypothesis is $H_0: \delta_{k,s} = \delta_{k,s}^{null} \;\; vs. \;\; H_1: \delta_{k,s} > \delta_{k,s}^{null}$ with $\delta_{k,s}^{null} <0$.
Its variance, standardized treatment effect and statistical information is the same as that from super-superiority design by setting $\delta_{k,s}^{null}$ as negative numbers.

# Weighting Options

As previously noted, we will consider weighting based on either inverse-variance weights (@MantelHaenszel) or strata sample size weights (@mehrotra2000minimum). 

- **Inverse-variance weights (INVAR):**
$$
  w_{s,k} = \frac{1/\widehat\sigma^2_{s,k}}{\sum_{s=1}^S 1/\widehat\sigma^2_{s,k}}.
$$
where $\widehat\sigma_{s,k}^2 \in \{\widehat\sigma_{H_0, k,s}^2, \widehat\sigma_{H_1, k,s}^2 \}$ depending on the infomation scale `info_scale = ...` in `gs_info_rd()`, `gs_power_rd()` and `gs_design_rd()`.

- **Sample-Size Weights (SS):**
$$
  w_{s,k} 
  =
  \frac{
    (N_{C, s, k} \; N_{E, s, k}) / (N_{C, s, k} + N_{E, s, k})
  }{
    \sum_{s=1}^S (N_{C, s, k} \; N_{E, s, k}) / (N_{C, s, k} + N_{E, s, k})
  },
$$
where $N_{C,s,k}, N_{E,s,k}$ are the sample size of the $s$-th strata and $k$-th analysis of the control group and experimental group, respectively.

# Power

The power under a fixed sample size
$$
  Pr\left(\cup_{k=1}^K Z_k \geq b_k  | H_1 \right)
$$


# Sample Size

The sample size of a fixed power is 

```{r}
p_c <- tibble::tibble(Stratum = "All", Rate = c(.15, .18, .2), Analysis = 1:3)
p_e <- tibble::tibble(Stratum = "All", Rate = c(.12, .13, .15), Analysis = 1:3)
N <- tibble::tibble(Stratum = "All", N = c(100, 200, 300), Analysis = 1:3)
rd0 <- 0
ratio <- 1

x <- gs_info_rd(p_c = p_c, p_e = p_e, N = N, rd0 = rd0, ratio = ratio, weight = "un-stratified")
x
```

```{r}
y <- gs_design_npe(theta = x$theta, 
                   info = x$info, info0 = x$info0, info_scale = 2,
                   alpha = alpha, beta = beta,
                   upper = gs_b, lower = gs_b,
                   upar = list(par = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound),
                   lpar = list(par = c(qnorm(.1), -Inf, -Inf)))
y
```

```{r}
N$N * y$info[3] / x$info[3]
```

# Simulations

We do a quick 20,000 simulations and compare the density histogram of outcomes to the standard normal density.
Assume $r=1, d = 1, p_C=p_E=0.125, N=200$.
We then compute $\sigma$ as `r round(sqrt(.125 * .875/200 * 4), 3)`.
Even for this *not huge* sample size the normal density fits quite well other than some flatness in the middle.


```{r, message = FALSE}
# Hypothesized failure rate
p <- .125
#  Other parameters
set.seed(123)
r <- 1
N <- 200
NC <- N / (r + 1)
NE <- r * N / (r + 1)
library(ggplot2)
# Generate random counts of events for each treatment
xC <- rbinom(n = 20000, size = NC, prob = p)
xE <- rbinom(n = 20000, size = NE, prob = p)
# Treatment difference estimate
thetahat <- xC / NC - xE / NE
# Standard error under H0
pbar <- (xC + xE) / N
se0 <- sqrt(pbar * (1 - pbar)*(1 / NC + 1 / NE))
# Z to test H0
Z <- thetahat / se0
x <- seq(-4, 4, .1)
se0a <- sqrt(p * (1 - p) * (1 / NC + 1 / NE))
y <- data.frame(Z = x, Density = dnorm(x = x, mean = 0, sd = 1)) 
ggplot() + 
  geom_histogram(data = data.frame(Z), aes(x = Z, y = ..density..), color = 1, fill = "white") +
    ylab("Density") +
  geom_line(data = y, aes(x=Z, y = Density)) +
  ggtitle("Binomial outcomes by simulation vs. asymptotic normal density",
          subtitle = "Histogram of 20,000 simulations")
```



# Summary

|  Parameters                 | Notes                                         |
|:----------------------------|:----------------------------------------------|
| **_risk difference:_**        |                                               |
| $\widehat\delta_{H_0,k} = \sum_{s=1}^S w_{k,s} \delta_{k,s}^{null}$| $\delta_{k,s}^{null}$ is the risk difference under $H_0$. It is 0, positive, and negative for superiority, super-superiority and non-inferiority design, respectively.|                                      
| $\widehat\delta_{H_1,k} = \sum_{s=1}^S w_{k,s} (\widehat p_{C,k,s} - \widehat p_{E,k,s})$ | $\widehat p_{C,k,s} = \frac{x_{C,k,s}}{N_{C,k,s}}, \; \widehat p_{E,k,s} = \frac{x_{E,k,s} }{N_{E,k,s}}$|
| **_standardized treatment effect:_**
| $\widehat\theta_{H_0,k} = \frac{\sum_{s=1}^S w_{k,s} \delta_{s,k}^{null}}{\sqrt{\sum_{s=1}^S w_{k,s}^2 \widehat \sigma_{H_0,k,s}^2}}$|For superiority design, $\widehat\sigma^2_{H_0,k,s} = \widehat p_{k,s}^{pool} \left(1 - \widehat p^{pool}_{k,s} \right) \left(\frac{1}{N_{C,k,s}} + \frac{1}{N_{E,k,s}} \right)$ <br> For super-superiority design and non-inferiority design, $\hat\sigma^2_{H_0,k,s} = \frac{\widehat p_{C0,k,s}(1- \widehat p_{C0,k,s})}{N_{C,k,s}} + \frac{ \widehat p_{E0,k,s} (1 - \widehat p_{E0,k,s})}{N_{E,k,s}}$  |       
| $\widehat\theta_{H_1,k} = \frac{\sum_{s=1}^S w_{k,s} (\widehat p_{C,k,s} - \widehat p_{E,k,s})}{\sqrt{\sum_{s=1}^S w_{k,s}^2 \widehat\sigma_{H_1,k,s}^2}}$ | $\widehat\sigma_{H_1,k,s} = \sqrt{\frac{\widehat p_{C,k,s} (1- \widehat p_{C,k,s})}{N_{C,k,s}} + \frac{\widehat p_{E,k,s} (1 - \widehat p_{E,k,s})}{N_{E,k,s}}}$|
| **_statistical information:_**|                                               |
| $\widehat{\mathcal I}_{H_0,k} = \left\{ \begin{array}{ll} \left[ \sum_{s=1}^S w_{k,s}^2 \frac{p_{k,s}^{pool} (1 - p_{k,s}^{pool})}{N_{k,s}} \right]^{-1} & \text{for superioirty design} \\ \left[ \sum_{s=1}^S w_{k,s}^2 \frac{\bar p_{C0,s} (1 - \bar p_{C0,s})}{N_{C,s}} + w_{k,s}^2\frac{\bar p_{E0,s} (1 - \bar p_{E0,s})}{N_{E,s}} \right]^{-1} & \text{for super-superiority and non-inferiority design} \end{array} \right.$ | $N_{k,s} = N_{C,k,s} + N_{E,k,s}$ and $\widehat p_{k,s} = (x_{C,k,s} + x_{E,k,s}) / N_{k,s}$|
| $\widehat{\mathcal I}_{H_1,k} = \left[ \sum_{s=1}^S w_{k,s}^2 \frac{\widehat p_{C,k,s} (1 - \widehat p_{C,k,s})}{N_{C,k,s}} + \sum_{s=1}^S w_{k,s}^2 \frac{\widehat p_{E,k,s} (1 - \widehat p_{E,k,s})}{N_{E,k,s}}  \right]^{-1}$ | |

# Examples

The variance derivations of previous sections provide the calculations needed for statistical information under the null and alternate hypotheses that are applicable to the approach for group sequential design applied in the package.
These are implemented in the `gs_info_rd()`, `gs_power_rd()` and `gs_design_rd()` functions.

## Verification of `gsDesign::nBinomial()`

```{r, eval=FALSE}
# compute a sample size to show non-inferiority
# with 5% margin, 90% power
nBinomial(p1 = .2, p2 = .2, delta0 = .05, alpha = .025, sided = 1, beta = .1)

gs_design_rd(
  p_c = tibble::tibble(Stratum = "All", Rate = .2, Analysis = 1),
  p_e = tibble::tibble(Stratum = "All", Rate = .2, Analysis = 1),
  N = tibble::tibble(Stratum = "All", N = 40, Analysis = 1),
  rd0 = .05, 
  alpha = 0.025,                   
  beta = 0.1,                      
  ratio = 1,
  weight = "un-stratified")$analysis$N
```


```{r}
# assuming a slight advantage in the experimental group lowers
# sample size requirement
nBinomial(p1 = .2, p2 = .19, delta0 = .05, alpha = .025, sided = 1, beta = .1)
gs_design_rd(
  p_c = tibble::tibble(Stratum = "All", Rate = .2, Analysis = 1),
  p_e = tibble::tibble(Stratum = "All", Rate = .19, Analysis = 1),
  N = tibble::tibble(Stratum = "All", N = 40, Analysis = 1),
  rd0 = .05, 
  alpha = 0.025,                   
  beta = 0.1,                      
  ratio = 1,
  weight = "un-stratified")$analysis$N
```

```{r}
# compute a sample size for comparing 15% vs 10% event rates
# with 1 to 2 randomization
nBinomial(p1 = .15, p2 = .1, beta = .2, ratio = 2, alpha = .05)
gs_design_rd(
  p_c = tibble::tibble(Stratum = "All", Rate = .15, Analysis = 1),
  p_e = tibble::tibble(Stratum = "All", Rate = .1, Analysis = 1),
  N = tibble::tibble(Stratum = "All", N = 40, Analysis = 1),
  rd0 = 0, 
  alpha = 0.05,                   
  beta = .2,                      
  ratio = 2,
  weight = "un-stratified")$analysis$N
```


```{r}
# now look at total sample size using 1-1 randomization
nBinomial(p1 = .15, p2 = .1, beta = .2, alpha = .05)
gs_design_rd(
  p_c = tibble::tibble(Stratum = "All", Rate = .15, Analysis = 1),
  p_e = tibble::tibble(Stratum = "All", Rate = .1, Analysis = 1),
  N = tibble::tibble(Stratum = "All", N = 40, Analysis = 1),
  rd0 = 0, 
  alpha = 0.05,                   
  beta = .2,                      
  ratio = 1,
  weight = "un-stratified")$analysis$N
```




# References
