---
title: "Group Sequential Design for Binary Outcomes"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: flatly
    highlight: tango
    code_folding: hide
bibliography: gsDesign.bib
vignette: |
  %\VignetteIndexEntry{Group Sequential Design for Binary Outcomes}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(tibble)
library(dplyr)
library(knitr)
library(gsdmvn)
```

## Overview

We consider group sequential design comparing two binomial distributions based on comparing two treatment groups for a binary outcome.
There are several issues to consider:

- The measure of treatment difference or natural parameter; we focus on risk difference.
- Null and alternate hypothesis variance incorporation.
- Superiority, non-inferiority and super-superiority designs.
- Stratified populations.
- Fixed and group sequential designs.

For single stratum designs, we focus on sample size or power using the method of
@FarringtonManning for a trial to test the difference between two
binomial event rates.  
The routine can be used for a test of superiority, non-inferiority or super-superiority. 
For a design that tests for superiority, the methods are consistent with those of @FTU, but without the
continuity correction; this is consistent with the **Hmisc** R package routines `bsamsize() and
`bpower` for superiority designs.

For trials with multiple strata, testing for a risk difference is often done by weighting each stratum according to the inverse of the variance @MantelHaenszel.
Since risk differences may also be assumed to be different for different strata, we will also explore weighting by strata size as in @Mehrotra2000.


The focus here is for sample sizes that are large enough for asymptotic theory to work well without continuity corrections.
Simulation is used throughout to check the examples presented.




## Single analysis unstratified


### Assumptions and notation

Throughout we assume a control group and a single experimental group indexed by $C$ and $E$, respectively.
We focus on pairwise comparisons.
We assume for control and experimental groups, respectively:

- Randomization between two treatment groups with sample sizes $N_C$ and $N_E$; the randomization ratio planned is $r=N_E/N_C$.
- Independent observations with a binary outcome that is observed with probability $p_C$ and $p_E$.
- Random variables $X_C\sim\hbox{Binomial}(N_C, p_C), X_E\sim\hbox{Binomial}(N_E,p_E)$ with observed outcomes $x_C, x_E$ and observed rates of $\bar p_C=x_C/N_C, \bar p_E=x_E/N_E$.  
- The constant $d=\pm 1$ indicating whether is an outcome is bad (failure; $d=1$) or good (response; $d=-1$).
- The natural parameter risk difference is denoted by $\theta = d\times (p_C - p_E)$. Thus, whether $d=1$ or $d=-1$, $\theta > 0$ indicates a more favorable outcome distribution in the experimental group than in the control group.
- Estimation of risk difference with $\hat\theta=d\times(\bar p_C - \bar p_E).$

Letting $N=N_C+N_E$, we note that $N_C=N/(r+1)$ and $N_E=Nr/(r+1)$.
We have $E(\hat\theta)=\theta$ and 

$$
\begin{aligned}
\sigma^2 &= \hbox{Var}(\hat\theta)= \frac{p_C(1- p_C)}{N_C}+\frac{p_E(1- p_E)}{N_E}\\
 &= \frac{r+1}{N}\left(p_C(1- p_C)+\frac{p_E(1- p_E)}{r}\right).
\end{aligned}
$$

### Testing


We test a null hypothesis $H_0: \theta=\theta_0$ where $\theta_0$ is in $(-1, 1)$ using the test statistic


$$Z=\frac{d\times(\bar p_C - \bar p_E) - \theta_0}{\hat\sigma_0}$$
where $\hat\sigma^2_0$, defined below, is the null hypothesis estimate of the $\hbox{Var}(\bar p_C -\bar p_E).$
Testing will be one-sided at level $\alpha\in (0,1)$ and the null hypothesis will be rejected if 
$$Z\ge \Phi^{-1}(1-\alpha).$$
We define $\bar p=(x_C+x_E)/(N_C+N_E)$.
Under the null hypothesis $\theta_0=0$ we have 
$$\hat\sigma^2_0 = \bar p (1-\bar p)\times \left(\frac{1}{N_C}+\frac{1}{N_E}\right)= \bar p (1-\bar p)\frac{r+1}{N}\left(1 + \frac{1}{r}\right).$$
Note that when we have equal randomization, this has the perhaps more recognizable form 
$$\hat\sigma^2_0 = \frac{4}{N}\bar p (1-\bar p).$$

We do a quick 20,000 simulations and compare the density histogram of outcomes to the standard normal density.
Assume $r=1, d = 1, p_C=p_E=0.125, N=200$.
We then compute $\sigma$ as `r round(sqrt(.125 * .875/200 * 4), 3)`.
Even for this *not huge* sample size the normal density fits quite well other than some flatness in the middle.


```{r, message = FALSE}
# Hypothesized failure rate
p <- .125
#  Other parameters
set.seed(123)
r <- 1
N <- 200
NC <- N / (r + 1)
NE <- r * N / (r + 1)
library(ggplot2)
# Generate random counts of events for each treatment
xC <- rbinom(n = 20000, size = NC, prob = p)
xE <- rbinom(n = 20000, size = NE, prob = p)
# Treatment difference estimate
thetahat <- xC / NC - xE / NE
# Standard error under H0
pbar <- (xC + xE) / N
se0 <- sqrt(pbar * (1 - pbar)*(1 / NC + 1 / NE))
# Z to test H0
Z <- thetahat / se0
x <- seq(-4, 4, .1)
se0a <- sqrt(p * (1 - p) * (1 / NC + 1 / NE))
y <- data.frame(Z = x, Density = dnorm(x = x, mean = 0, sd = 1)) 
ggplot() + 
  geom_histogram(data = data.frame(Z), aes(x = Z, y = ..density..), color = 1, fill = "white") +
    ylab("Density") +
  geom_line(data = y, aes(x=Z, y = Density)) +
  ggtitle("Binomial outcomes by simulation vs. asymptotic normal density",
          subtitle = "Histogram of 20,000 simulations")
```

Now we extend the computation of $\hat\sigma^2_0$ to $\theta_0\neq 0$ using the restriction that rate estimates $\bar p_{C0}, \bar p_{E0}$ under the null hypothesis satisfy 
$$\bar p_{C0}=\bar p_{E0}+d\theta_0\\
\bar p_{C0} + r\bar p_{E0} = \bar p_C + r\bar p_E .$$
Solving these 2 equations with 2 unknowns yields

$$
\begin{aligned}
\bar p_{E0} &= \frac{\bar p_C+r\bar p_E - d\theta_0}{r+1}\\
\bar p_{C0} &=  \bar p_{E0}+ d\theta_0.
\end{aligned}
$$
We estimate the above variance with:
$$\hat\sigma^2_0= \frac{\bar p_{C0}(1- \bar p_{C0})}{N_C}+\frac{ \bar p_{E0}(1- \bar p_{E0})}{N_E}= \frac{r+1}{N}\left( \bar p_{C0}(1- \bar p_{C0})+\frac{\bar p_{E0}(1 -\bar p_{E0})}{r}\right).
$$



We will use the asymptotic approximation $Z=\hat\theta/\hat\sigma\sim\hbox{Normal}(0, 1)$.
Squaring this and applying a continuity correction is a typical two-sided testing approach, but we will not use the continuity correction here. 
Using the normally distributed $Z$ enables one-sided testing. 
The continuity correction is generally unneeded (@CCmyth).

### Sample size and power

Same; include simulation for both Type I error and power.



The corresponding maximum likelihood estimator of variance is 

$$
\hat\sigma^2 = \frac{r+1}{N}\left(\bar p_C(1- \bar p_C)+\frac{\bar p_E(1- \bar p_E)}{r}\right).
$$

## Stratified population

### Assumptions

### Weighting options

## Group sequential design

## Information-based design

## References
